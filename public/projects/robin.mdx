# Robin

When I'm in class, I hate taking notes. I know it helps with information retention, but I'd much rather just listen to the lecture directly. So, I made Robin, an AI note taking app. It used OpenAI's [Whipser](https://github.com/openai/whisper) to record a professor's voice during a lecture, then convert that lecture into text. After the text conversion, it used Google's Gemini models, which were impressively cheap, to clean up the text, produce flashcards, and more. 

Overall, it was a super fun project, because I could actually test it in class. I could go into class, press record, and be free to listen to the lecture without distracitons. I learned a ton about how to send requests to and handle responses from LLM providers, which are finally starting to standardize.

The idea fizzled out when I found Google's [NotebookLM](https://notebooklm.google/), pretty much Robin but made by the third largest company in the world with use of their own models and lots more money. 

## Problems

I didn't realize how difficult text parsing was with LLM responses. Working with text is easy, but working with text when you don't know the format of the output is much harder.

## Links
- [Repository](https://github.com/gpossst/robin)

###  April 2025